---
# [General]
airflow_app_name: airflow
airflow_version: 2.1.1
airflow_package: apache-airflow

# Owner
airflow_user: airflow
airflow_group: airflow
airflow_shell: /usr/sbin/nologin
airflow_createhome: yes

# The default buster's python version, if you want other version you should make sure it is
# installed before
airflow_python_version:

# Because problems with some pip versions, we added this option to choose what version the role should install.
# See https://airflow.apache.org/docs/apache-airflow/stable/installation.html#installation-tools
airflow_pip_version: 20.2.4

# Airflow url to download the correct version
airflow_constraint_url: "https://raw.githubusercontent.com/apache/airflow/constraints-{{ airflow_version }}/constraints-{{ airflow_python_version }}.txt"

# Available extra packages:
# https://airflow.apache.org/docs/apache-airflow/stable/extra-packages-ref.html
# List should follow Ansible's YAML basics:
# https://docs.ansible.com/ansible/latest/reference_appendices/YAMLSyntax.html#yaml-basics
airflow_bundle_package:  # all|all_dbs|devel|devel_hadoop|devel_all|devel_ci See bundle extras section
# airflow_extra_packages:
  # [Apache]
  # - apache.atlas
  # - apache.beam
  # - apache.cassandra
  # - apache.druid
  # - apache.hdfs
  # - apache.hive
  # - apache.kylin
  # - apache.livy
  # - apache.pig
  # - apache.pinot
  # - apache.spark
  # - apache.sqoop
  # - apache.webhdfs
  # [Services]
  # - amazon
  # - microsoft.azure
  # - cloudant
  # - databricks
  # - datadog
  # - dask
  # - dingding
  # - discord
  # - facebook
  # - google
  # - github_enterprise
  # - google_auth
  # - hashicorp
  # - jira
  # - opsgenie
  # - pagerduty
  # - plexus
  # - qubole
  # - salesforce
  # - sendgrid
  # - segment
  # - sentry
  # - slack
  # - snowflake
  # - telegram
  # - vertica
  # - yandex
  # - zendesk
  # [Software]
  # - async
  # - celery
  # - cncf.kubernetes
  # - docker
  # - elasticsearch
  # - exasol
  # - jenkins
  # - ldap
  # - mongo
  # - microsoft.mssql
  # - mysql
  # - odbc
  # - openfaas
  # - oracle
  # - postgres
  # - password
  # - presto
  # - rabbitmq
  # - redis
  # - samba
  # - singularity
  # - statsd
  # - tableau
  # - virtualenv
  # [Others]
  # - cgroups
  # - ftp
  # - grpc
  # - http
  # - imap
  # - jdbc
  # - kerberos
  # - papermill
  # - sftp
  # - sqlite
  # - ssh
  # - microsoft.winrm

airflow_default_required_libs:
  - python3-dev
  - python3-pip
  - python3-setuptools
  - python-pip
  # - acl
# Airflow 2.0 system level requirements https://airflow.apache.org/docs/apache-airflow/stable/installation.html#system-dependencies
  - freetds-bin
  - krb5-user
  - ldap-utils
  - libffi6
  - libsasl2-2
  - libsasl2-modules
  - libssl1.1
  - locales
  - lsb-release
  - sasl2-bin
  - sqlite3
  - unixodbc

airflow_additional_required_libs: []

airflow_required_libs: "{{ airflow_default_required_libs + airflow_additional_required_libs }}"

# airflow_required_python_packages:
  # - { name: SQLAlchemy, version: 1.3.23 } # v1.4 Breaks airflow installation
#   Version is not mandatory
#   - {name: pyasn1, version: 0.4.4}

# Admin user
airflow_admin_users:
  - name:
    username:
    password:
    role:
    firstname:
    lastname:
    email:

# Admin user
# airflow_regular_users:
#   - name:
#     username:
#     password:
#     role:
#     firstname:
#     lastname:
#     email:

# Service options
# airflow_scheduler_runs: 1000
airflow_private_tmp: false

airflow_services:
  airflow_webserver:
    service_name: airflow-webserver
    enabled: true
    running: true
    state: started
    path: airflow-webserver.service.j2
  airflow_scheduler:
    service_name: airflow-scheduler
    enabled: true
    running: true
    state: started
    path: airflow-scheduler.service.j2
  airflow_worker:
    service_name: airflow-worker
    enabled: false
    running: false
    state: started
    path: airflow-worker.service.j2
  airflow_flower:
    service_name: airflow-flower
    enabled: false
    running: false
    state: started
    path: airflow-flower.service.j2

# Files & Paths
airflow_executable: "{{ airflow_app_home }}/bin/airflow"
airflow_pip_executable: "pip3"
airflow_user_home: "/var/lib/{{ airflow_user }}"
airflow_app_home: "/opt/{{ airflow_app_name }}"
airflow_conf_path: "/etc/{{ airflow_app_name }}"
airflow_pidfile_folder: "/run/{{ airflow_app_name }}"
airflow_environment_file_folder: /etc/sysconfig
airflow_environment_extra_vars: []
airflow_health_url: "http://{{ airflow_webserver_host }}:{{ airflow_webserver_port }}/health"
#   - name: PATH
#     value: "/custom/path/bin:$PATH"
airflow_skeleton_paths:
  - "{{ airflow_app_home }}"
  - "{{ airflow_conf_path }}"
  - "{{ airflow_dags_folder }}"
  - "{{ airflow_logs_folder }}"
  - "{{ airflow_child_process_log_folder }}"
  - "{{ airflow_environment_file_folder }}"
  - "{{ airflow_plugins_folder }}"

# Allowing playbooks to provide external config files&templates
airflow_extra_conf_path: "{{ playbook_dir }}/files/airflow"
airflow_extra_conf_template_path: "{{ playbook_dir }}/templates/airflow"
airflow_config_template_path: airflow.cfg.j2
airflow_config_template_path_v2: airflow2.cfg.j2

# DICT
celery_extra_packages:

# This Celery version is guaranteed to work with Airflow 1.8.x
celery_version: 3.1.17

# DAGs
# Python dependencies needed by the DAGs. This variable is expected to be a
# list of items following the structure provided in the example comment
# dags_dependencies:
#   - {name: pip_package, version: version_needed}
